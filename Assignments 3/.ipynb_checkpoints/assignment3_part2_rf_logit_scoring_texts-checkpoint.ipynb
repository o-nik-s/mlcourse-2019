{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course \n",
    "Authors: Vitaly Radchenko (@vradchenko), [Yury Kashnitsky](https://yorko.github.io) (@yorko). Edited by Sergey Volkov (@sevaspb). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Assignment #3. Fall 2019\n",
    "## <center> Part 2. Random Forest and Logistic Regression in credit scoring and movie reviews classification\n",
    " \n",
    "Random Forest and logistic regression are two algorithms that I personally use most often in day-to-day DS tasks. In this part of the assignment, we'll explore pros and cons of these two algorithms in two different tasks. \n",
    " \n",
    "Prior to working on the assignment, you'd better check out the corresponding course material:\n",
    " 1. [Classification, Decision Trees and k Nearest Neighbors](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic03_decision_trees_kNN/topic3_decision_trees_kNN.ipynb?flush_cache=true), the same as an interactive web-based [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn) \n",
    " 2. Ensembles:\n",
    "  - [Bagging](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part1_bagging.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-1-bagging)\n",
    "  - [Random Forest](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part2_random_forest.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-2-random-forest)\n",
    "  - [Feature Importance](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part3_feature_importance.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-3-feature-importance)\n",
    " 3. - [Gradient boosting](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic10_boosting/topic10_gradient_boosting.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-10-gradient-boosting) \n",
    "   - Logistic regression, Random Forest, and LightGBM in the \"Kaggle Forest Cover Type Prediction\" competition: [Kernel](https://www.kaggle.com/kashnitsky/topic-10-practice-with-logit-rf-and-lightgbm) \n",
    " 4. You can also practice with demo assignments, which are simpler and already shared with solutions:\n",
    "  - \"Decision trees with a toy task and the UCI Adult dataset\": [assignment](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees) + [solution](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees-solution)\n",
    "  - \"Logistic Regression and Random Forest in the credit scoring problem\": [assignment](https://www.kaggle.com/kashnitsky/assignment-5-logit-and-rf-for-credit-scoring) + [solution](https://www.kaggle.com/kashnitsky/a5-demo-logit-and-rf-for-credit-scoring-sol)\n",
    " 5. There are also 7 video lectures on trees, forests, boosting and their applications: [mlcourse.ai/lectures](https://mlcourse.ai/lectures) \n",
    "\n",
    "### Your task is to:\n",
    " 1. write code and perform computations in the cells below\n",
    " 2. choose answers in the [webform](https://docs.google.com/forms/d/1a2PrdKsc7gV2fO7bSwO-uGVEWAY6CIxx-9YV5RNnDIs) (same one as for A3 part 1). Solutions will be shared only with those who've filled in this form. \n",
    " \n",
    "### <center> Deadline for A3: 2019 October 27, 20:59 GMT+1 (London time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's just cut the foreplay.\n",
    "\n",
    "#### Problem\n",
    "\n",
    "Predict whether the customer will repay their credit within 90 days. This is a binary classification problem; we will assign customers into good or bad categories based on our prediction.\n",
    "\n",
    "#### Data description\n",
    "\n",
    "| Feature | Variable Type | Value Type | Description |\n",
    "|:--------|:--------------|:-----------|:------------|\n",
    "| age | Input Feature | integer | Customer age |\n",
    "| DebtRatio | Input Feature | real | Total monthly loan payments (loan, alimony, etc.) / Total monthly income percentage |\n",
    "| NumberOfTime30-59DaysPastDueNotWorse | Input Feature | integer | The number of cases when client has overdue 30-59 days (not worse) on other loans during the last 2 years |\n",
    "| NumberOfTimes90DaysLate | Input Feature | integer | Number of cases when customer had 90+dpd overdue on other credits |\n",
    "| NumberOfTime60-89DaysPastDueNotWorse | Input Feature | integer | Number of cased when customer has 60-89dpd (not worse) during the last 2 years |\n",
    "| NumberOfDependents | Input Feature | integer | The number of customer dependents |\n",
    "| SeriousDlqin2yrs | Target Variable | binary: <br>0 or 1 | Customer hasn't paid the loan debt within 90 days |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = 10, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us implement a function that will replace the NaN values by the median in each column of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute_nan_with_median(table):\n",
    "    for col in table.columns:\n",
    "        table[col]= table[col].fillna(table[col].median())\n",
    "    return table   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8158.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3870.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6666.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  age  NumberOfTime30-59DaysPastDueNotWorse    DebtRatio  \\\n",
       "0                 0   64                                     0     0.249908   \n",
       "1                 0   58                                     0  3870.000000   \n",
       "2                 0   41                                     0     0.456127   \n",
       "3                 0   43                                     0     0.000190   \n",
       "4                 1   49                                     0     0.271820   \n",
       "\n",
       "   NumberOfTimes90DaysLate  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                        0                                     0   \n",
       "1                        0                                     0   \n",
       "2                        0                                     0   \n",
       "3                        0                                     0   \n",
       "4                        0                                     0   \n",
       "\n",
       "   MonthlyIncome  NumberOfDependents  \n",
       "0         8158.0                 0.0  \n",
       "1            NaN                 0.0  \n",
       "2         6666.0                 0.0  \n",
       "3        10500.0                 2.0  \n",
       "4          400.0                 0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('credit_scoring_sample.csv', sep=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View data types of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeriousDlqin2yrs                          int64\n",
       "age                                       int64\n",
       "NumberOfTime30-59DaysPastDueNotWorse      int64\n",
       "DebtRatio                               float64\n",
       "NumberOfTimes90DaysLate                   int64\n",
       "NumberOfTime60-89DaysPastDueNotWorse      int64\n",
       "MonthlyIncome                           float64\n",
       "NumberOfDependents                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the distribution of the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.777511\n",
       "1    0.222489\n",
       "Name: SeriousDlqin2yrs, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAGHCAYAAAD1HvUOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nALAQwhkAAICFEM4AAAAs5P8Bb6Y3NffzshcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = data['SeriousDlqin2yrs'].hist(orientation='horizontal', color='red')\n",
    "ax.set_xlabel(\"number_of_observations\")\n",
    "ax.set_ylabel(\"unique_value\")\n",
    "ax.set_title(\"Target distribution\")\n",
    "\n",
    "\n",
    "print('Distribution of target:')\n",
    "data['SeriousDlqin2yrs'].value_counts(normalize=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select all the features and drop the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'NumberOfTime30-59DaysPastDueNotWorse',\n",
       " 'DebtRatio',\n",
       " 'NumberOfTimes90DaysLate',\n",
       " 'NumberOfTime60-89DaysPastDueNotWorse',\n",
       " 'MonthlyIncome',\n",
       " 'NumberOfDependents']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent_columns_names = data.columns.values\n",
    "independent_columns_names = [x for x in data if x != 'SeriousDlqin2yrs']\n",
    "independent_columns_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply a function that replaces all NaN values with the median value of the corresponding feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = impute_nan_with_median(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the target and features - now we get a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = table[independent_columns_names]\n",
    "y = table['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap\n",
    "\n",
    "_Part 1 had 7 questions, so here we start with #8._\n",
    "\n",
    "**<font color = 'red'> Question 8. </font>** Make an interval estimate based on the bootstrap (2000 samples) of the average income (MonthlyIncome)  of customers who had overdue loan payments, and of those who paid in time, make 80% confidence interval. Use target value (SeriousDlqin2yrs) to split data. Find the difference between the lower limit of the derived interval for those who paid in time and the upper limit for those who are overdue.\n",
    "So, you are asked to build 80% intervals for the income of \"good\" customers $ [good\\_income\\_lower, good\\_income\\_upper] $ and for \"bad\" - $ [bad\\_income\\_lower, bad\\_income\\_upper] $ and find the difference $ good\\_income\\_lower - bad\\_income\\_upper $.\n",
    "\n",
    "Use the example from the [article](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-5-ensembles-of-algorithms-and-random-forest-8e05246cbba7). Set `np.random.seed(17)`. Round your answer to the closest integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Answer options:</font>**\n",
    "- 686\n",
    "- 734\n",
    "- 834 \n",
    "- 996\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai_news, pinned thread __#a3_part2_fall2019__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you'll be asked to fix this seed (`random_state`) everywhere in this notebook\n",
    "SEED = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45063, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1633: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAF6CAYAAACJLOnBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP/rFZ9NmHK22AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = sns.kdeplot(data[data['SeriousDlqin2yrs'] == False]['MonthlyIncome'], label = 'Paid')\n",
    "fig = sns.kdeplot(data[data['SeriousDlqin2yrs'] == True]['MonthlyIncome'], label = 'Not paid')        \n",
    "fig.set(xlabel='Месячный доход', ylabel='Плотность')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly income from paid clients: mean interval [6310.92322402 6478.45869224]\n",
      "Monthly income from not paid clients: mean interval [5486.3783862 5625.3523838]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "685.5708402182063"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You code here\n",
    "def get_bootstrap_samples(data, n_samples):\n",
    "    # функция для генерации подвыборок с помощью бутстрэпа\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples\n",
    "def stat_intervals(stat, alpha):\n",
    "    # функция для интервальной оценки\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries\n",
    "\n",
    "# сохранение в отдельные numpy массивы данных поклиентам, погасившим и не погасившим кредит\n",
    "paid = table[table['SeriousDlqin2yrs'] == False]['MonthlyIncome'].values\n",
    "not_paid = table[table['SeriousDlqin2yrs'] == True]['MonthlyIncome'].values\n",
    "\n",
    "# ставим seed для воспроизводимости результатов\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# генерируем выборки с помощью бутстрэра и сразу считаем по каждой из них среднее\n",
    "paid_mean_scores = [np.mean(sample) \n",
    "                       for sample in get_bootstrap_samples(paid, 2000)]\n",
    "not_paid_mean_scores = [np.mean(sample) \n",
    "                       for sample in get_bootstrap_samples(not_paid, 2000)]\n",
    "\n",
    "#  выводим интервальную оценку среднего\n",
    "good_income = stat_intervals(paid_mean_scores, 0.2)\n",
    "bad_income = stat_intervals(not_paid_mean_scores, 0.2)\n",
    "print(\"Monthly income from paid clients: mean interval\", good_income)\n",
    "print(\"Monthly income from not paid clients: mean interval\", bad_income)\n",
    "\n",
    "good_income[0] - bad_income[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree, hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main performance metrics of a model is the area under the ROC curve. The ROC-AUC values lay between 0 and 1. The closer the value of ROC-AUC to 1, the better the classification is done.\n",
    "\n",
    "Find the values of `DecisionTreeClassifier` hyperparameters using the `GridSearchCV`, which maximize the area under the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `DecisionTreeClassifier` class to create a decision tree. Due to the imbalance of the classes in the target, we add the balancing parameter. We also use the parameter `random_state = 17` for the reproducibility of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=SEED, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look through such values of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_depth_values = [5, 6, 7, 8, 9]\n",
    "max_features_values = [4, 5, 6, 7]\n",
    "tree_params = {'max_depth': max_depth_values,\n",
    "               'max_features': max_features_values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix cross-validation parameters: stratified, 5 partitions with shuffle, \n",
    "`random_state`. We will use this splitting throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=5, random_state=17, shuffle=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "skf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 9.</font>**\n",
    "Run GridSearch with the ROC AUC metric using the hyperparameters from the `tree_params` dictionary. What is the maximum ROC AUC value (round up to 2 decimals)? We call cross-validation stable if the standard deviation of the metric on the cross-validation is less than 0.01. Was cross-validation stable under optimal combinations of hyperparameters (i.e., providing a maximum of the mean ROC AUC value for cross-validation)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Answer options:</font>**\n",
    "- 0.82, no\n",
    "- 0.84, no\n",
    "- 0.82, yes\n",
    "- 0.84, yes\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai_news, pinned thread __#a3_part2_fall2019__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=17, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=17, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [5, 6, 7, 8, 9], 'max_features': [4, 5, 6, 7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "tree_grid = GridSearchCV(DecisionTreeClassifier(random_state=17), tree_params, cv=skf, scoring='roc_auc')\n",
    "tree_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.81377, std: 0.00123, params: {'max_depth': 5, 'max_features': 4},\n",
       " mean: 0.80472, std: 0.00497, params: {'max_depth': 5, 'max_features': 5},\n",
       " mean: 0.81269, std: 0.00241, params: {'max_depth': 5, 'max_features': 6},\n",
       " mean: 0.81608, std: 0.00311, params: {'max_depth': 5, 'max_features': 7},\n",
       " mean: 0.81725, std: 0.00269, params: {'max_depth': 6, 'max_features': 4},\n",
       " mean: 0.81649, std: 0.00220, params: {'max_depth': 6, 'max_features': 5},\n",
       " mean: 0.81611, std: 0.00241, params: {'max_depth': 6, 'max_features': 6},\n",
       " mean: 0.82092, std: 0.00289, params: {'max_depth': 6, 'max_features': 7},\n",
       " mean: 0.82127, std: 0.00213, params: {'max_depth': 7, 'max_features': 4},\n",
       " mean: 0.81903, std: 0.00109, params: {'max_depth': 7, 'max_features': 5},\n",
       " mean: 0.82150, std: 0.00176, params: {'max_depth': 7, 'max_features': 6},\n",
       " mean: 0.81859, std: 0.00351, params: {'max_depth': 7, 'max_features': 7},\n",
       " mean: 0.81670, std: 0.00305, params: {'max_depth': 8, 'max_features': 4},\n",
       " mean: 0.81672, std: 0.00335, params: {'max_depth': 8, 'max_features': 5},\n",
       " mean: 0.81777, std: 0.00278, params: {'max_depth': 8, 'max_features': 6},\n",
       " mean: 0.81776, std: 0.00427, params: {'max_depth': 8, 'max_features': 7},\n",
       " mean: 0.81283, std: 0.00306, params: {'max_depth': 9, 'max_features': 4},\n",
       " mean: 0.81562, std: 0.00344, params: {'max_depth': 9, 'max_features': 5},\n",
       " mean: 0.81449, std: 0.00629, params: {'max_depth': 9, 'max_features': 6},\n",
       " mean: 0.81201, std: 0.00453, params: {'max_depth': 9, 'max_features': 7}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81376697, 0.80472025, 0.81268899, 0.81607503, 0.81724528,\n",
       "       0.81649128, 0.81611484, 0.82092302, 0.82127086, 0.81902512,\n",
       "       0.8215021 , 0.81859037, 0.81670382, 0.81671521, 0.81776538,\n",
       "       0.81775636, 0.81282703, 0.8156172 , 0.81448539, 0.81201084])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grid.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8215021040670176"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tree_grid.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.82, yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RandomForest implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 10.</font>**\n",
    "Implement your own random forest using `DecisionTreeClassifier` with the best parameters from the previous task. There will be 10 trees, the predicted probabilities of which you need to average.\n",
    "\n",
    "Brief specification:\n",
    " - Use the base code below\n",
    " - In the `fit` method in the loop (`i` from 0 to `n_estimators-1`):\n",
    "   * fix the seed equal to (`random_state + i`). The idea is that at each iteration there's a new value of random seed to add more \"randomness\", but at the same time results are reproducible\n",
    "   * After fixing the seed, select `max_features` features **without replacement**, save the list of selected feature ids in `self.feat_ids_by_tree`\n",
    "   * Also make a bootstrap sample (i.e. **sampling with replacement**) of training instances. For that, resort to `np.random.choice` and its argument `replace`\n",
    "   * Train a decision tree with specified (in a constructor) arguments `max_depth`, `max_features` and `random_state` (do not specify `class_weight`) on a corresponding subset of training data. \n",
    " - The `fit` method returns the current instance of the class `RandomForestClassifierCustom`, that is `self`\n",
    " - In the `predict_proba` method, we need to loop through all the trees. For each prediction, obviously, we need to take only those features which we used for training the corresponding tree. The method returns predicted probabilities (`predict_proba`), averaged for all trees\n",
    "\n",
    "Perform cross-validation with `StratifiedKFold`.  What is the average cross-validation ROC AUC of the custom Random Forest implementation? Select the closest value.\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai_news, pinned thread __#a3_part2_fall2019__*\n",
    "\n",
    "**<font color='red'>Answer options:</font>**\n",
    "- 0.823\n",
    "- 0.833\n",
    "- 0.843\n",
    "- 0.853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class RandomForestClassifierCustom(BaseEstimator):\n",
    "    def __init__(self, n_estimators=10, max_depth=10, max_features=10, \n",
    "                 random_state=SEED):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.trees = []\n",
    "        self.feat_ids_by_tree = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # You code here\n",
    "        for i in range(0, n_estimators-1):\n",
    "            seed = random_state+i\n",
    "            self.feat_ids_by_tree = max_features\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # You code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 11.</font>**\n",
    "Let us compare our own implementation of a random forest with `sklearn` version of it. To do this, use `RandomForestClassifier (class_weight='balanced', n_estimators=10, random_state=17)`, specify all the same values for `max_depth` and `max_features` as before. What average value of ROC AUC on cross-validation we finally got? Select the closest value.\n",
    "\n",
    "**<font color='red'>Answer options:</font>**\n",
    "- 0.814\n",
    "- 0.827\n",
    "- 0.843\n",
    "- 0.856\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai_news, pinned thread __#a3_part2_fall2019__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max_features must be in (0, n_features]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-8f590fb32172>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 326\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_depth must be greater than zero. \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_features must be in (0, n_features]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n",
      "\u001b[1;31mValueError\u001b[0m: max_features must be in (0, n_features]"
     ]
    }
   ],
   "source": [
    "rt = RandomForestClassifier(random_state=SEED, class_weight='balanced', n_estimators=10, max_depth=10, max_features=10)\n",
    "rt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `sklearn` RandomForest, hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 12.</font>** \n",
    "In the third task, we found the optimal hyperparameters for one tree. However it could be that these parameters are not optimal for an ensemble. Let's check this assumption with `GridSearchCV` `(RandomForestClassifier (class_weight='balanced', n_estimators=10, random_state=17)` ). Now we extend the value of `max_depth` up to 15, because the trees need to be deeper in the forest (you should be aware of it from the [article](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-5-ensembles-of-algorithms-and-random-forest-8e05246cbba7)). What are the best values of hyperparameters now?\n",
    "\n",
    "**<font color='red'>Answer options:</font>**\n",
    "- `max_depth=8, max_features=4`\n",
    "- `max_depth=9, max_features=5`\n",
    "- `max_depth=10, max_features=6`\n",
    "- `max_depth=11, max_features=7`\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai_news, pinned thread __#a3_part2_fall2019__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_depth_values = range(5, 15)\n",
    "max_features_values = [4, 5, 6, 7]\n",
    "forest_params = {\n",
    "    'max_depth': max_depth_values,\n",
    "    'max_features': max_features_values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=17, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=17, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': range(5, 15), 'max_features': [4, 5, 6, 7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "random_forest_greed = GridSearchCV(RandomForestClassifier(random_state=17, class_weight='balanced', n_estimators=10), forest_params, cv=skf, scoring='roc_auc')\n",
    "random_forest_greed.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'max_features': 4}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You code here\n",
    "random_forest_greed.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression, hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 13.</font>**  Now let's compare our results with logistic regression (we indicate `class_weight = 'balanced'`, `solver='liblinear'` and `random_state=17`). Do a full search by the parameter `C` from a wide range of values `np.logspace (-8, 8, 17)`.\n",
    "Now we will build a pipeline - first apply scaling, then train the model.\n",
    "\n",
    "Learn about the pipelines and make cross-validation. What is the best average ROC AUC? Select the closest value.\n",
    "\n",
    "**<font color='red'>Answer options:</font>**\n",
    "- 0.788\n",
    "- 0.798\n",
    "- 0.808\n",
    "- 0.818\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai_news, pinned thread __#a3_part2_fall2019__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "logit = LogisticRegression(random_state=SEED, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "logit_pipe = Pipeline([('scaler', scaler), ('logit', logit)])\n",
    "logit_pipe_params = {'logit__C': np.logspace(-8, 8, 17)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression and RandomForest on sparse features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of a small number of features, random forest was proved to be better than logistic regression. However, one of the main disadvantages of trees is how they work with sparse data, for example, with texts. Let's compare logistic regression and random forest in a new task.\n",
    "Download the dataset with movie reviews from [here](https://drive.google.com/file/d/1WDz3EB0MMuQUuUTwZ30c4JJrN8d9shAW/view?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    32492\n",
       "0    17508\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download data\n",
    "df = pd.read_csv(\"../../data/movie_reviews_train.csv.zip\", nrows=50000)\n",
    "\n",
    "# Split data to train and test\n",
    "X_text = df[\"text\"]\n",
    "y_text = df[\"label\"]\n",
    "\n",
    "# Classes counts\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Split on 3 folds\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "\n",
    "# In Pipeline we will modify the text and train Random forest\n",
    "classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=100000, ngram_range=(1, 3))),\n",
    "    ('clf', RandomForestClassifier(n_estimators=10, random_state=SEED, n_jobs=-1))])\n",
    "\n",
    "min_samples_leaf = [1, 2, 3]\n",
    "max_features = [0.3, 0.5, 0.7]\n",
    "max_depth = [None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 14.</font>** Let's use Random forest algorithm for this task. Similarly, look over all the values and get the maximum ROC AUC, select the closest value. Keep in mind that in this case training may take a lot of time (up to an hour). \n",
    "\n",
    "**<font color='red'>Answer options:</font>**\n",
    "- 0.71\n",
    "- 0.75\n",
    "- 0.81\n",
    "- 0.85\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai_news, pinned thread __#a3_part2_fall2019__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question  15.</font>** Will  Logistic Regression save our time? For Logistic Regression: iterate parameter `C` with values from the list [0.1, 1, 10, 100] and find the best ROC AUC in cross-validation. Select the closest answer.\n",
    "\n",
    "**<font color='red'>Answer options:</font>**\n",
    "- 0.71\n",
    "- 0.75\n",
    "- 0.81\n",
    "- 0.85\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai_news, pinned thread __#a3_part2_fall2019__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In Pipeline we will modify the text and train logistic regression\n",
    "classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=100000, ngram_range=(1, 3))),\n",
    "    ('clf', LogisticRegression(solver='liblinear', random_state=SEED))])\n",
    "\n",
    "parameters = {'clf__C': (0.1, 1, 10, 100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
